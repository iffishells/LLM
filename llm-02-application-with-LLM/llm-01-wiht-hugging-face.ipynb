{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf70c38dd903ede1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T07:48:21.322032149Z",
     "start_time": "2024-01-11T07:48:21.310144893Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-01-11 10:44:06.409811: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-11 10:44:06.409842: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-11 10:44:06.411431: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-11 10:44:06.418781: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-11 10:44:07.581610: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87a546b0-d043-4a69-a036-536d2c386534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b4628b7f57c3c53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T07:50:08.260212756Z",
     "start_time": "2024-01-11T07:50:08.210140319Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255M/255M [01:15<00:00, 3.36MB/s]\n",
      "Downloading data: 2.72MB [00:00, 5.24MB/s]                                                                                                                                                                                          \n",
      "Generating train split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 204045/204045 [00:44<00:00, 4556.89 examples/s]\n",
      "Generating validation split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11332/11332 [00:25<00:00, 438.86 examples/s]\n",
      "Generating test split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11334/11334 [00:25<00:00, 444.16 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['document', 'summary', 'id'],\n",
      "        num_rows: 204045\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['document', 'summary', 'id'],\n",
      "        num_rows: 11332\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['document', 'summary', 'id'],\n",
      "        num_rows: 11334\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_location = \"../datasets/labelled_newscatcher_dataset.csv\"\n",
    "\n",
    "# Load the XSum dataset using a custom cache directory\n",
    "xsum_dataset = load_dataset(\"xsum\", version=\"1.2.0\",trust_remote_code=True)\n",
    "# xsum_dataset = load_dataset(\"xsum\", version=\"1.2.0\", cache_dir=csv_location,trust_remote_code=True)\n",
    "\n",
    "# Print information about the loaded dataset\n",
    "print(xsum_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612cf23e-4110-42c4-9de2-b3eb284e4a5f",
   "metadata": {},
   "source": [
    "# Sample of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83bb518881f45f4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T07:53:45.964529777Z",
     "start_time": "2024-01-11T07:50:50.561217305Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The full cost of damage in Newton Stewart, one...</td>\n",
       "      <td>Clean-up operations are continuing across the ...</td>\n",
       "      <td>35232142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fire alarm went off at the Holiday Inn in Ho...</td>\n",
       "      <td>Two tourist buses have been destroyed by fire ...</td>\n",
       "      <td>40143035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferrari appeared in a position to challenge un...</td>\n",
       "      <td>Lewis Hamilton stormed to pole position at the...</td>\n",
       "      <td>35951548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Edward Bates, formerly of Spalding, Linco...</td>\n",
       "      <td>A former Lincolnshire Police officer carried o...</td>\n",
       "      <td>36266422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patients and staff were evacuated from Cerahpa...</td>\n",
       "      <td>An armed man who locked himself into a room at...</td>\n",
       "      <td>38826984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Simone Favaro got the crucial try with the las...</td>\n",
       "      <td>Defending Pro12 champions Glasgow Warriors bag...</td>\n",
       "      <td>34540833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Veronica Vanessa Chango-Alverez, 31, was kille...</td>\n",
       "      <td>A man with links to a car that was involved in...</td>\n",
       "      <td>20836172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Belgian cyclist Demoitie died after a collisio...</td>\n",
       "      <td>Welsh cyclist Luke Rowe says changes to the sp...</td>\n",
       "      <td>35932467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gundogan, 26, told BBC Sport he \"can see the f...</td>\n",
       "      <td>Manchester City midfielder Ilkay Gundogan says...</td>\n",
       "      <td>40758845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The crash happened about 07:20 GMT at the junc...</td>\n",
       "      <td>A jogger has been hit by an unmarked police ca...</td>\n",
       "      <td>30358490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  The full cost of damage in Newton Stewart, one...   \n",
       "1  A fire alarm went off at the Holiday Inn in Ho...   \n",
       "2  Ferrari appeared in a position to challenge un...   \n",
       "3  John Edward Bates, formerly of Spalding, Linco...   \n",
       "4  Patients and staff were evacuated from Cerahpa...   \n",
       "5  Simone Favaro got the crucial try with the las...   \n",
       "6  Veronica Vanessa Chango-Alverez, 31, was kille...   \n",
       "7  Belgian cyclist Demoitie died after a collisio...   \n",
       "8  Gundogan, 26, told BBC Sport he \"can see the f...   \n",
       "9  The crash happened about 07:20 GMT at the junc...   \n",
       "\n",
       "                                             summary        id  \n",
       "0  Clean-up operations are continuing across the ...  35232142  \n",
       "1  Two tourist buses have been destroyed by fire ...  40143035  \n",
       "2  Lewis Hamilton stormed to pole position at the...  35951548  \n",
       "3  A former Lincolnshire Police officer carried o...  36266422  \n",
       "4  An armed man who locked himself into a room at...  38826984  \n",
       "5  Defending Pro12 champions Glasgow Warriors bag...  34540833  \n",
       "6  A man with links to a car that was involved in...  20836172  \n",
       "7  Welsh cyclist Luke Rowe says changes to the sp...  35932467  \n",
       "8  Manchester City midfielder Ilkay Gundogan says...  40758845  \n",
       "9  A jogger has been hit by an unmarked police ca...  30358490  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xsum_sample = xsum_dataset[\"train\"].select(range(10))\n",
    "display(xsum_sample.to_pandas())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f04ba6-6808-42d4-86f0-7f21f9bad501",
   "metadata": {},
   "source": [
    "# Loading the Pre-trained Model for summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40d07ab0-6e06-4b2b-9a67-076e05f8281a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 242M/242M [00:55<00:00, 4.38MB/s]\n",
      "2024-01-11 09:57:35.086918: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65798144 exceeds 10% of free system memory.\n",
      "2024-01-11 09:57:35.165701: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65798144 exceeds 10% of free system memory.\n",
      "2024-01-11 09:57:35.175273: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65798144 exceeds 10% of free system memory.\n",
      "2024-01-11 09:57:36.130510: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65798144 exceeds 10% of free system memory.\n",
      "2024-01-11 09:57:36.414790: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65798144 exceeds 10% of free system memory.\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "tokenizer_config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.32k/2.32k [00:00<00:00, 2.81MB/s]\n",
      "spiece.model: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 792k/792k [00:00<00:00, 857kB/s]\n",
      "tokenizer.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.39M/1.39M [00:00<00:00, 3.98MB/s]\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=\"t5-small\",\n",
    "    min_length=20,\n",
    "    max_length=40,\n",
    "    truncation=True\n",
    "    # model_kwargs={\"cache_dir\": DA.paths.datasets},\n",
    ")  # Note: We specify cache_dir to use predownloaded models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e344785-a363-4121-b8da-d23f87d3cb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 09:59:14.111497: I external/local_xla/xla/service/service.cc:168] XLA service 0x55a77eda3e50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-11 09:59:14.111523: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-01-11 09:59:14.133043: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1704967154.345518      94 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-01-11 09:59:14.349685: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . a flood alert remains in place across the'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply to 1 article\n",
    "summarizer(xsum_sample[\"document\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d74e01-974a-480a-9c5a-470d167ffac5",
   "metadata": {},
   "source": [
    "# Save the summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a23e1583-3ff6-4dff-94c1-601685c1a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = summarizer(xsum_sample[\"document\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bece0a4-237e-4260-af19-55c6e4921735",
   "metadata": {},
   "source": [
    "# Display the summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b8202b4-a7a5-44a3-a9c2-ce52d0726a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generated_summary</th>\n",
       "      <th>summary</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the full cost of damage in Newton Stewart is s...</td>\n",
       "      <td>Clean-up operations are continuing across the ...</td>\n",
       "      <td>The full cost of damage in Newton Stewart, one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a fire alarm went off at the Holiday Inn in Ho...</td>\n",
       "      <td>Two tourist buses have been destroyed by fire ...</td>\n",
       "      <td>A fire alarm went off at the Holiday Inn in Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sebastian Vettel will start third ahead of tea...</td>\n",
       "      <td>Lewis Hamilton stormed to pole position at the...</td>\n",
       "      <td>Ferrari appeared in a position to challenge un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the 67-year-old is accused of committing the o...</td>\n",
       "      <td>A former Lincolnshire Police officer carried o...</td>\n",
       "      <td>John Edward Bates, formerly of Spalding, Linco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a man receiving psychiatric treatment at the c...</td>\n",
       "      <td>An armed man who locked himself into a room at...</td>\n",
       "      <td>Patients and staff were evacuated from Cerahpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gregor Townsend gave a debut to powerhouse win...</td>\n",
       "      <td>Defending Pro12 champions Glasgow Warriors bag...</td>\n",
       "      <td>Simone Favaro got the crucial try with the las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Veronica Vanessa Chango-Alverez, 31, was kille...</td>\n",
       "      <td>A man with links to a car that was involved in...</td>\n",
       "      <td>Veronica Vanessa Chango-Alverez, 31, was kille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the 25-year-old was hit by a motorbike during ...</td>\n",
       "      <td>Welsh cyclist Luke Rowe says changes to the sp...</td>\n",
       "      <td>Belgian cyclist Demoitie died after a collisio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gundogan will not be fit for the start of the ...</td>\n",
       "      <td>Manchester City midfielder Ilkay Gundogan says...</td>\n",
       "      <td>Gundogan, 26, told BBC Sport he \"can see the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the crash happened about 07:20 GMT at the junc...</td>\n",
       "      <td>A jogger has been hit by an unmarked police ca...</td>\n",
       "      <td>The crash happened about 07:20 GMT at the junc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   generated_summary  \\\n",
       "0  the full cost of damage in Newton Stewart is s...   \n",
       "1  a fire alarm went off at the Holiday Inn in Ho...   \n",
       "2  Sebastian Vettel will start third ahead of tea...   \n",
       "3  the 67-year-old is accused of committing the o...   \n",
       "4  a man receiving psychiatric treatment at the c...   \n",
       "5  Gregor Townsend gave a debut to powerhouse win...   \n",
       "6  Veronica Vanessa Chango-Alverez, 31, was kille...   \n",
       "7  the 25-year-old was hit by a motorbike during ...   \n",
       "8  gundogan will not be fit for the start of the ...   \n",
       "9  the crash happened about 07:20 GMT at the junc...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Clean-up operations are continuing across the ...   \n",
       "1  Two tourist buses have been destroyed by fire ...   \n",
       "2  Lewis Hamilton stormed to pole position at the...   \n",
       "3  A former Lincolnshire Police officer carried o...   \n",
       "4  An armed man who locked himself into a room at...   \n",
       "5  Defending Pro12 champions Glasgow Warriors bag...   \n",
       "6  A man with links to a car that was involved in...   \n",
       "7  Welsh cyclist Luke Rowe says changes to the sp...   \n",
       "8  Manchester City midfielder Ilkay Gundogan says...   \n",
       "9  A jogger has been hit by an unmarked police ca...   \n",
       "\n",
       "                                            document  \n",
       "0  The full cost of damage in Newton Stewart, one...  \n",
       "1  A fire alarm went off at the Holiday Inn in Ho...  \n",
       "2  Ferrari appeared in a position to challenge un...  \n",
       "3  John Edward Bates, formerly of Spalding, Linco...  \n",
       "4  Patients and staff were evacuated from Cerahpa...  \n",
       "5  Simone Favaro got the crucial try with the las...  \n",
       "6  Veronica Vanessa Chango-Alverez, 31, was kille...  \n",
       "7  Belgian cyclist Demoitie died after a collisio...  \n",
       "8  Gundogan, 26, told BBC Sport he \"can see the f...  \n",
       "9  The crash happened about 07:20 GMT at the junc...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    pd.DataFrame.from_dict(results)\n",
    "    .rename({\"summary_text\": \"generated_summary\"}, axis=1)\n",
    "    .join(pd.DataFrame.from_dict(xsum_sample))[\n",
    "        [\"generated_summary\", \"summary\", \"document\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d89e8-a342-43db-8217-b870299f437f",
   "metadata": {},
   "source": [
    "# Loading peom Data for classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48685cc1-8adc-4d3d-9b4b-cda8423c117d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1429: FutureWarning: The repository for poem_sentiment contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/poem_sentiment\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.10k/3.10k [00:00<00:00, 7.20MB/s]\n",
      "Downloading metadata: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.10k/2.10k [00:00<00:00, 2.99MB/s]\n",
      "Downloading readme: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5.51k/5.51k [00:00<00:00, 2.57MB/s]\n",
      "Downloading data: 40.6kB [00:00, 1.92MB/s]                                                                                                                                                                                          \n",
      "Downloading data: 4.75kB [00:00, 1.69MB/s]                                                                                                                                                                                          \n",
      "Downloading data: 4.56kB [00:00, 3.69MB/s]                                                                                                                                                                                          \n",
      "Generating train split: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 892/892 [00:00<00:00, 15553.12 examples/s]\n",
      "Generating validation split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 105/105 [00:00<00:00, 13548.33 examples/s]\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 104/104 [00:00<00:00, 12902.50 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>verse_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>with pale blue berries. in these peaceful shad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>it flows so long as falls the rain,</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>and that is why, the lonesome day,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>when i peruse the conquered fame of heroes, an...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>of inward strife for truth and liberty.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>the red sword sealed their vows!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>and very venus of a pipe.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>who the man, who, called a brother.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>and so on. then a worthless gaud or two,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>to hide the orb of truth--and every throne</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         verse_text  label\n",
       "0   0  with pale blue berries. in these peaceful shad...      1\n",
       "1   1                it flows so long as falls the rain,      2\n",
       "2   2                 and that is why, the lonesome day,      0\n",
       "3   3  when i peruse the conquered fame of heroes, an...      3\n",
       "4   4            of inward strife for truth and liberty.      3\n",
       "5   5                   the red sword sealed their vows!      3\n",
       "6   6                          and very venus of a pipe.      2\n",
       "7   7                who the man, who, called a brother.      2\n",
       "8   8           and so on. then a worthless gaud or two,      0\n",
       "9   9         to hide the orb of truth--and every throne      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poem_dataset = load_dataset(\n",
    "    \"poem_sentiment\", version=\"1.0.0\",\n",
    ")\n",
    "poem_sample = poem_dataset[\"train\"].select(range(10))\n",
    "display(poem_sample.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc25dcb-af13-489c-aedd-88ab90a9330a",
   "metadata": {},
   "source": [
    "# Loading pretrained model for classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9284d402-783c-4a31-b5ca-9cf07d589648",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not load model nickwong64/bert-base-uncased-poems-sentiment with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification'>). See the original errors:\n\nwhile loading with TFAutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\", line 566, in from_pretrained\n    return model_class.from_pretrained(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 2824, in from_pretrained\n    raise EnvironmentError(\nOSError: nickwong64/bert-base-uncased-poems-sentiment does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.\n\nwhile loading with TFBertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 2824, in from_pretrained\n    raise EnvironmentError(\nOSError: nickwong64/bert-base-uncased-poems-sentiment does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sentiment_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-classification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnickwong64/bert-base-uncased-poems-sentiment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_pt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py:870\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 870\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    881\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:282\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m class_name, trace \u001b[38;5;129;01min\u001b[39;00m all_traceback\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    281\u001b[0m             error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile loading with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, an error is thrown:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. See the original errors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         )\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m     framework \u001b[38;5;241m=\u001b[39m infer_framework(model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not load model nickwong64/bert-base-uncased-poems-sentiment with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification'>). See the original errors:\n\nwhile loading with TFAutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\", line 566, in from_pretrained\n    return model_class.from_pretrained(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 2824, in from_pretrained\n    raise EnvironmentError(\nOSError: nickwong64/bert-base-uncased-poems-sentiment does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.\n\nwhile loading with TFBertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 269, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 2824, in from_pretrained\n    raise EnvironmentError(\nOSError: nickwong64/bert-base-uncased-poems-sentiment does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.\n\n\n"
     ]
    }
   ],
   "source": [
    "# sentiment_classifier = pipeline(\n",
    "#     task=\"text-classification\",\n",
    "#     model=\"nickwong64/bert-base-uncased-poems-sentiment\",\n",
    "#     from_pt=True\n",
    "# )\n",
    "\n",
    "# results = sentiment_classifier(poem_sample[\"verse_text\"])\n",
    "# joined_data = (\n",
    "#     pd.DataFrame.from_dict(results)\n",
    "#     .rename({\"label\": \"predicted_label\"}, axis=1)\n",
    "#     .join(pd.DataFrame.from_dict(poem_sample).rename({\"label\": \"true_label\"}, axis=1))\n",
    "# )\n",
    "\n",
    "# # Change label indices to text labels\n",
    "# sentiment_labels = {0: \"negative\", 1: \"positive\", 2: \"no_impact\", 3: \"mixed\"}\n",
    "# joined_data = joined_data.replace({\"true_label\": sentiment_labels})\n",
    "\n",
    "# display(joined_data[[\"predicted_label\", \"true_label\", \"score\", \"verse_text\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb1fca-b6fc-4a93-b554-775eef65a210",
   "metadata": {},
   "source": [
    "# Zero Shot classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1de1b5-8cd4-4684-b6bb-40172ea52ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_pipeline = pipeline(\n",
    "    task=\"zero-shot-classification\",\n",
    "    model=\"cross-encoder/nli-deberta-v3-small\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19ae5db0-3387-49c7-988b-444f116ed308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_article(article: str) -> None:\n",
    "    \"\"\"\n",
    "    This helper function defines the categories (labels) which the model must use to label articles.\n",
    "    Note that our model was NOT fine-tuned to use these specific labels,\n",
    "    but it \"knows\" what the labels mean from its more general training.\n",
    "\n",
    "    This function then prints out the predicted labels alongside their confidence scores.\n",
    "    \"\"\"\n",
    "    results = zero_shot_pipeline(\n",
    "        article,\n",
    "        candidate_labels=[\n",
    "            \"politics\",\n",
    "            \"finance\",\n",
    "            \"sports\",\n",
    "            \"science and technology\",\n",
    "            \"pop culture\",\n",
    "            \"breaking news\",\n",
    "        ],\n",
    "    )\n",
    "    # Print the results nicely\n",
    "    del results[\"sequence\"]\n",
    "    display(pd.DataFrame(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4fa14da-b664-45d1-a2cb-9b1142a9ed44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.317830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breaking news</td>\n",
       "      <td>0.206972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pop culture</td>\n",
       "      <td>0.155593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>science and technology</td>\n",
       "      <td>0.123465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finance</td>\n",
       "      <td>0.105939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>politics</td>\n",
       "      <td>0.090201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   labels    scores\n",
       "0                  sports  0.317830\n",
       "1           breaking news  0.206972\n",
       "2             pop culture  0.155593\n",
       "3  science and technology  0.123465\n",
       "4                 finance  0.105939\n",
       "5                politics  0.090201"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "categorize_article(\n",
    "    \"\"\"\n",
    "Simone Favaro got the crucial try with the last move of the game, following earlier touchdowns by Chris Fusaro, Zander Fagerson and Junior Bulumakau.\n",
    "Rynard Landman and Ashton Hewitt got a try in either half for the Dragons.\n",
    "Glasgow showed far superior strength in depth as they took control of a messy match in the second period.\n",
    "Home coach Gregor Townsend gave a debut to powerhouse Fijian-born Wallaby wing Taqele Naiyaravoro, and centre Alex Dunbar returned from long-term injury, while the Dragons gave first starts of the season to wing Aled Brew and hooker Elliot Dee.\n",
    "Glasgow lost hooker Pat McArthur to an early shoulder injury but took advantage of their first pressure when Rory Clegg slotted over a penalty on 12 minutes.\n",
    "It took 24 minutes for a disjointed game to produce a try as Sarel Pretorius sniped from close range and Landman forced his way over for Jason Tovey to convert - although it was the lock's last contribution as he departed with a chest injury shortly afterwards.\n",
    "Glasgow struck back when Fusaro drove over from a rolling maul on 35 minutes for Clegg to convert.\n",
    "But the Dragons levelled at 10-10 before half-time when Naiyaravoro was yellow-carded for an aerial tackle on Brew and Tovey slotted the easy goal.\n",
    "The visitors could not make the most of their one-man advantage after the break as their error count cost them dearly.\n",
    "It was Glasgow's bench experience that showed when Mike Blair's break led to a short-range score from teenage prop Fagerson, converted by Clegg.\n",
    "Debutant Favaro was the second home player to be sin-binned, on 63 minutes, but again the Warriors made light of it as replacement wing Bulumakau, a recruit from the Army, pounced to deftly hack through a bouncing ball for an opportunist try.\n",
    "The Dragons got back within striking range with some excellent combined handling putting Hewitt over unopposed after 72 minutes.\n",
    "However, Favaro became sinner-turned-saint as he got on the end of another effective rolling maul to earn his side the extra point with the last move of the game, Clegg converting.\n",
    "Dragons director of rugby Lyn Jones said: \"We're disappointed tpip install sentencepiece\n",
    "o have lost but our performance was a lot better [than against Leinster] and the game could have gone either way.\n",
    "\"Unfortunately too many errors behind the scrum cost us a great deal, though from where we were a fortnight ago in Dublin our workrate and desire was excellent.\n",
    "\"It was simply error count from individuals behind the scrum that cost us field position, it's not rocket science - they were correct in how they played and we had a few errors, that was the difference.\"\n",
    "Glasgow Warriors: Rory Hughes, Taqele Naiyaravoro, Alex Dunbar, Fraser Lyle, Lee Jones, Rory Clegg, Grayson Hart; Alex Allan, Pat MacArthur, Zander Fagerson, Rob Harley (capt), Scott Cummings, Hugh Blake, Chris Fusaro, Adam Ashe.\n",
    "Replacements: Fergus Scott, Jerry Yanuyanutawa, Mike Cusack, Greg Peterson, Simone Favaro, Mike Blair, Gregor Hunter, Junior Bulumakau.\n",
    "Dragons: Carl Meyer, Ashton Hewitt, Ross Wardle, Adam Warren, Aled Brew, Jason Tovey, Sarel Pretorius; Boris Stankovich, Elliot Dee, Brok Harris, Nick Crosswell, Rynard Landman (capt), Lewis Evans, Nic Cudd, Ed Jackson.\n",
    "Replacements: Rhys Buckley, Phil Price, Shaun Knight, Matthew Screech, Ollie Griffiths, Luc Jones, Charlie Davies, Nick Scott.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b30eea-4d70-4470-89c2-3b8308768455",
   "metadata": {},
   "source": [
    "# few shot learninig for text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c46ce-a603-4927-9590-87892fcb4335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.35k/1.35k [00:00<00:00, 1.89MB/s]\n",
      "model.safetensors:  42%|█████████████████████████████████████████████████████████████████████▌                                                                                                 | 2.21G/5.31G [08:17<12:35, 4.10MB/s]"
     ]
    }
   ],
   "source": [
    "few_shot_pipeline = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"EleutherAI/gpt-neo-1.3B\",\n",
    "    max_new_tokens=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c6670-fd97-4c80-83d5-c9b1fd763ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the token ID for \"###\", which we will use as the EOS token below.\n",
    "eos_token_id = few_shot_pipeline.tokenizer.encode(\"###\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f0494-b612-4aa7-a692-7e3d1b09b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without any examples, the model output is inconsistent and usually incorrect.\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "[Tweet]: \"This new music video was incredible\"\n",
    "[Sentiment]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac8e13-a7c9-49ba-871e-a00b599fb708",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4e4bed-ed4c-4a41-ab3a-98473ea4d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With only 1 example, the model may or may not get the answer right.\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "[Tweet]: \"This is the link to the article\"\n",
    "[Sentiment]: Neutral\n",
    "###\n",
    "[Tweet]: \"This new music video was incredible\"\n",
    "[Sentiment]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0b50c9-0d40-41de-ae9a-9f0db850196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360736ef-1117-4b79-bd10-3a1129682572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With 1 example for each sentiment, the model is more likely to understand!\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "[Tweet]: \"I hate it when my phone battery dies.\"\n",
    "[Sentiment]: Negative\n",
    "###\n",
    "[Tweet]: \"My day has been 👍\"\n",
    "[Sentiment]: Positive\n",
    "###\n",
    "[Tweet]: \"This is the link to the article\"\n",
    "[Sentiment]: Neutral\n",
    "###\n",
    "[Tweet]: \"This new music video was incredible\"\n",
    "[Sentiment]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ebbdf4-f951-40a9-ad03-2ae73ab1ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model isn't ready to serve drinks!\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each food, suggest a good drink pairing:\n",
    "\n",
    "[food]: tapas\n",
    "[drink]: wine\n",
    "###\n",
    "[food]: pizza\n",
    "[drink]: soda\n",
    "###\n",
    "[food]: jalapenos poppers\n",
    "[drink]: beer\n",
    "###\n",
    "[food]: scone\n",
    "[drink]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe8d1cb-8371-44c4-90b1-cfc0098a8384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example sometimes works and sometimes does not, when sampling.  Too abstract?\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"Given a word describing how someone is feeling, suggest a description of that person.  The description should not include the original word.\n",
    "\n",
    "[word]: happy\n",
    "[description]: smiling, laughing, clapping\n",
    "###\n",
    "[word]: nervous\n",
    "[description]: glancing around quickly, sweating, fidgeting\n",
    "###\n",
    "[word]: sleepy\n",
    "[description]: heavy-lidded, slumping, rubbing eyes\n",
    "###\n",
    "[word]: confused\n",
    "[description]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600eac7d-7653-4ad6-91cd-d78bbdd186e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We override max_new_tokens to generate longer answers.\n",
    "# These book descriptions were taken from their corresponding Wikipedia pages.\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"Generate a book summary from the title:\n",
    "\n",
    "[book title]: \"Stranger in a Strange Land\"\n",
    "[book description]: \"This novel tells the story of Valentine Michael Smith, a human who comes to Earth in early adulthood after being born on the planet Mars and raised by Martians, and explores his interaction with and eventual transformation of Terran culture.\"\n",
    "###\n",
    "[book title]: \"The Adventures of Tom Sawyer\"\n",
    "[book description]: \"This novel is about a boy growing up along the Mississippi River. It is set in the 1840s in the town of St. Petersburg, which is based on Hannibal, Missouri, where Twain lived as a boy. In the novel, Tom Sawyer has several adventures, often with his friend Huckleberry Finn.\"\n",
    "###\n",
    "[book title]: \"Dune\"\n",
    "[book description]: \"This novel is set in the distant future amidst a feudal interstellar society in which various noble houses control planetary fiefs. It tells the story of young Paul Atreides, whose family accepts the stewardship of the planet Arrakis. While the planet is an inhospitable and sparsely populated desert wasteland, it is the only source of melange, or spice, a drug that extends life and enhances mental abilities.  The story explores the multilayered interactions of politics, religion, ecology, technology, and human emotion, as the factions of the empire confront each other in a struggle for the control of Arrakis and its spice.\"\n",
    "###\n",
    "[book title]: \"Blue Mars\"\n",
    "[book description]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    "    max_new_tokens=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0657873-af9e-41d9-8f89-9712bf58bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c80d89f-c45f-459b-b64e-cd6188f0d782",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the pre-trained tokenizer and model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\", cache_dir=DA.paths.datasets)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\", cache_dir=DA.paths.datasets)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# For summarization, T5-small expects a prefix \"summarize: \", so we prepend that to each article as a prompt.\n",
    "articles = list(map(lambda article: \"summarize: \" + article, xsum_sample[\"document\"]))\n",
    "display(pd.DataFrame(articles, columns=[\"prompts\"]))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(\n",
    "    articles, max_length=1024, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "print(\"input_ids:\")\n",
    "print(inputs[\"input_ids\"])\n",
    "print(\"attention_mask:\")\n",
    "print(inputs[\"attention_mask\"])\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Generate summaries\n",
    "summary_ids = model.generate(\n",
    "    inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    num_beams=2,\n",
    "    min_length=0,\n",
    "    max_length=40,\n",
    ")\n",
    "print(summary_ids)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Decode the generated summaries\n",
    "decoded_summaries = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
    "display(pd.DataFrame(decoded_summaries, columns=[\"decoded_summaries\"]))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md ### Model-specific tokenizer and model loaders\n",
    "# MAGIC\n",
    "# MAGIC You can also more directly load specific tokenizer and model types, rather than relying on `Auto*` classes to choose the right ones for you.\n",
    "# MAGIC\n",
    "# MAGIC API docs:\n",
    "# MAGIC * [T5Tokenizer](https://huggingface.co/docs/transformers/main/en/model_doc/t5#transformers.T5Tokenizer)\n",
    "# MAGIC * [T5ForConditionalGeneration](https://huggingface.co/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", cache_dir=DA.paths.datasets)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"t5-small\", cache_dir=DA.paths.datasets\n",
    ")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# The tokenizer and model can then be used similarly to how we used the ones loaded by the Auto* classes.\n",
    "inputs = tokenizer(\n",
    "    articles, max_length=1024, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "summary_ids = model.generate(\n",
    "    inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    num_beams=2,\n",
    "    min_length=0,\n",
    "    max_length=40,\n",
    ")\n",
    "decoded_summaries = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
    "\n",
    "display(pd.DataFrame(decoded_summaries, columns=[\"decoded_summaries\"]))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md ## Summary\n",
    "# MAGIC\n",
    "# MAGIC We've covered some common LLM applications and seen how to get started with them quickly using pre-trained models from the Hugging Face Hub.  We've also see how to tweak some configurations.\n",
    "# MAGIC\n",
    "# MAGIC But how did we find those models for our tasks?  In the lab, you will find new pre-trained models for tasks, using the Hugging Face Hub.  You will also explore tweaking model configurations to gain intuition about their effects.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md-sandbox\n",
    "# MAGIC &copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
    "# MAGIC Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "# MAGIC <br/>\n",
    "# MAGIC <a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
