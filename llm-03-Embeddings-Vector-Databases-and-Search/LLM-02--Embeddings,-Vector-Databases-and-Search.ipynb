{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6ed5c2b-972b-4322-ad4a-de8dcffb1b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample # will use to transformer data for faiss index or vector embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52d1ec56-bab7-4ded-b7ca-f0dcf6afd45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>link</th>\n",
       "      <th>domain</th>\n",
       "      <th>published_date</th>\n",
       "      <th>title</th>\n",
       "      <th>lang</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.eurekalert.org/pub_releases/2020-0...</td>\n",
       "      <td>eurekalert.org</td>\n",
       "      <td>2020-08-06 13:59:45</td>\n",
       "      <td>A closer look at water-splitting's solar fuel ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.pulse.ng/news/world/an-irresistibl...</td>\n",
       "      <td>pulse.ng</td>\n",
       "      <td>2020-08-12 15:14:19</td>\n",
       "      <td>An irresistible scent makes locusts swarm, stu...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.express.co.uk/news/science/1322607...</td>\n",
       "      <td>express.co.uk</td>\n",
       "      <td>2020-08-13 21:01:00</td>\n",
       "      <td>Artificial intelligence warning: AI will know ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.ndtv.com/world-news/glaciers-could...</td>\n",
       "      <td>ndtv.com</td>\n",
       "      <td>2020-08-03 22:18:26</td>\n",
       "      <td>Glaciers Could Have Sculpted Mars Valleys: Study</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.thesun.ie/tech/5742187/perseid-met...</td>\n",
       "      <td>thesun.ie</td>\n",
       "      <td>2020-08-12 19:54:36</td>\n",
       "      <td>Perseid meteor shower 2020: What time and how ...</td>\n",
       "      <td>en</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108769</th>\n",
       "      <td>NATION</td>\n",
       "      <td>https://www.vanguardngr.com/2020/08/pdp-govern...</td>\n",
       "      <td>vanguardngr.com</td>\n",
       "      <td>2020-08-08 02:40:00</td>\n",
       "      <td>PDP governors’ forum urges security agencies t...</td>\n",
       "      <td>en</td>\n",
       "      <td>108769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108770</th>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>https://www.patentlyapple.com/patently-apple/2...</td>\n",
       "      <td>patentlyapple.com</td>\n",
       "      <td>2020-08-08 01:27:12</td>\n",
       "      <td>In Q2-20, Apple Dominated the Premium Smartpho...</td>\n",
       "      <td>en</td>\n",
       "      <td>108770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108771</th>\n",
       "      <td>HEALTH</td>\n",
       "      <td>https://www.belfastlive.co.uk/news/health/coro...</td>\n",
       "      <td>belfastlive.co.uk</td>\n",
       "      <td>2020-08-12 17:01:00</td>\n",
       "      <td>Coronavirus Northern Ireland: Full breakdown s...</td>\n",
       "      <td>en</td>\n",
       "      <td>108771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108772</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>https://www.thenews.com.pk/latest/696364-paul-...</td>\n",
       "      <td>thenews.com.pk</td>\n",
       "      <td>2020-08-05 04:59:00</td>\n",
       "      <td>Paul McCartney details post-Beatles distress a...</td>\n",
       "      <td>en</td>\n",
       "      <td>108772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108773</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>https://www.balls.ie/football/shane-duffy-brig...</td>\n",
       "      <td>balls.ie</td>\n",
       "      <td>2020-08-09 10:25:26</td>\n",
       "      <td>Report: Talks Underway To Keep Shane Duffy In ...</td>\n",
       "      <td>en</td>\n",
       "      <td>108773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108774 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                topic                                               link  \\\n",
       "0             SCIENCE  https://www.eurekalert.org/pub_releases/2020-0...   \n",
       "1             SCIENCE  https://www.pulse.ng/news/world/an-irresistibl...   \n",
       "2             SCIENCE  https://www.express.co.uk/news/science/1322607...   \n",
       "3             SCIENCE  https://www.ndtv.com/world-news/glaciers-could...   \n",
       "4             SCIENCE  https://www.thesun.ie/tech/5742187/perseid-met...   \n",
       "...               ...                                                ...   \n",
       "108769         NATION  https://www.vanguardngr.com/2020/08/pdp-govern...   \n",
       "108770       BUSINESS  https://www.patentlyapple.com/patently-apple/2...   \n",
       "108771         HEALTH  https://www.belfastlive.co.uk/news/health/coro...   \n",
       "108772  ENTERTAINMENT  https://www.thenews.com.pk/latest/696364-paul-...   \n",
       "108773         SPORTS  https://www.balls.ie/football/shane-duffy-brig...   \n",
       "\n",
       "                   domain       published_date  \\\n",
       "0          eurekalert.org  2020-08-06 13:59:45   \n",
       "1                pulse.ng  2020-08-12 15:14:19   \n",
       "2           express.co.uk  2020-08-13 21:01:00   \n",
       "3                ndtv.com  2020-08-03 22:18:26   \n",
       "4               thesun.ie  2020-08-12 19:54:36   \n",
       "...                   ...                  ...   \n",
       "108769    vanguardngr.com  2020-08-08 02:40:00   \n",
       "108770  patentlyapple.com  2020-08-08 01:27:12   \n",
       "108771  belfastlive.co.uk  2020-08-12 17:01:00   \n",
       "108772     thenews.com.pk  2020-08-05 04:59:00   \n",
       "108773           balls.ie  2020-08-09 10:25:26   \n",
       "\n",
       "                                                    title lang      id  \n",
       "0       A closer look at water-splitting's solar fuel ...   en       0  \n",
       "1       An irresistible scent makes locusts swarm, stu...   en       1  \n",
       "2       Artificial intelligence warning: AI will know ...   en       2  \n",
       "3        Glaciers Could Have Sculpted Mars Valleys: Study   en       3  \n",
       "4       Perseid meteor shower 2020: What time and how ...   en       4  \n",
       "...                                                   ...  ...     ...  \n",
       "108769  PDP governors’ forum urges security agencies t...   en  108769  \n",
       "108770  In Q2-20, Apple Dominated the Premium Smartpho...   en  108770  \n",
       "108771  Coronavirus Northern Ireland: Full breakdown s...   en  108771  \n",
       "108772  Paul McCartney details post-Beatles distress a...   en  108772  \n",
       "108773  Report: Talks Underway To Keep Shane Duffy In ...   en  108773  \n",
       "\n",
       "[108774 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "csv_location = \"../datasets/labelled_newscatcher_dataset.csv\"\n",
    "\n",
    "pdf = pd.read_csv(csv_location, sep=\";\")\n",
    "pdf[\"id\"] = pdf.index\n",
    "display(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98168f5d-55dc-4b3f-8b05-847c47bb0a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>link</th>\n",
       "      <th>domain</th>\n",
       "      <th>published_date</th>\n",
       "      <th>title</th>\n",
       "      <th>lang</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.eurekalert.org/pub_releases/2020-0...</td>\n",
       "      <td>eurekalert.org</td>\n",
       "      <td>2020-08-06 13:59:45</td>\n",
       "      <td>A closer look at water-splitting's solar fuel ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.pulse.ng/news/world/an-irresistibl...</td>\n",
       "      <td>pulse.ng</td>\n",
       "      <td>2020-08-12 15:14:19</td>\n",
       "      <td>An irresistible scent makes locusts swarm, stu...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.express.co.uk/news/science/1322607...</td>\n",
       "      <td>express.co.uk</td>\n",
       "      <td>2020-08-13 21:01:00</td>\n",
       "      <td>Artificial intelligence warning: AI will know ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.ndtv.com/world-news/glaciers-could...</td>\n",
       "      <td>ndtv.com</td>\n",
       "      <td>2020-08-03 22:18:26</td>\n",
       "      <td>Glaciers Could Have Sculpted Mars Valleys: Study</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.thesun.ie/tech/5742187/perseid-met...</td>\n",
       "      <td>thesun.ie</td>\n",
       "      <td>2020-08-12 19:54:36</td>\n",
       "      <td>Perseid meteor shower 2020: What time and how ...</td>\n",
       "      <td>en</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>https://www.androidcentral.com/mate-40-will-be...</td>\n",
       "      <td>androidcentral.com</td>\n",
       "      <td>2020-08-07 17:12:33</td>\n",
       "      <td>The Mate 40 will be the last Huawei phone with...</td>\n",
       "      <td>en</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.cnn.com/2020/08/17/africa/stone-ag...</td>\n",
       "      <td>cnn.com</td>\n",
       "      <td>2020-08-17 17:10:00</td>\n",
       "      <td>Early humans knew how to make comfy, pest-free...</td>\n",
       "      <td>en</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>HEALTH</td>\n",
       "      <td>https://www.tenterfieldstar.com.au/story/68776...</td>\n",
       "      <td>tenterfieldstar.com.au</td>\n",
       "      <td>2020-08-13 03:26:06</td>\n",
       "      <td>Regional Vic set for virus testing blitz</td>\n",
       "      <td>en</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>HEALTH</td>\n",
       "      <td>https://news.sky.com/story/coronavirus-trials-...</td>\n",
       "      <td>news.sky.com</td>\n",
       "      <td>2020-08-13 13:22:58</td>\n",
       "      <td>Coronavirus: Trials of second contact-tracing ...</td>\n",
       "      <td>en</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>HEALTH</td>\n",
       "      <td>https://www.techexplorist.com/study-demonstrat...</td>\n",
       "      <td>techexplorist.com</td>\n",
       "      <td>2020-08-10 07:47:00</td>\n",
       "      <td>The study demonstrates new treatment for prion...</td>\n",
       "      <td>en</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          topic                                               link  \\\n",
       "0       SCIENCE  https://www.eurekalert.org/pub_releases/2020-0...   \n",
       "1       SCIENCE  https://www.pulse.ng/news/world/an-irresistibl...   \n",
       "2       SCIENCE  https://www.express.co.uk/news/science/1322607...   \n",
       "3       SCIENCE  https://www.ndtv.com/world-news/glaciers-could...   \n",
       "4       SCIENCE  https://www.thesun.ie/tech/5742187/perseid-met...   \n",
       "..          ...                                                ...   \n",
       "995  TECHNOLOGY  https://www.androidcentral.com/mate-40-will-be...   \n",
       "996     SCIENCE  https://www.cnn.com/2020/08/17/africa/stone-ag...   \n",
       "997      HEALTH  https://www.tenterfieldstar.com.au/story/68776...   \n",
       "998      HEALTH  https://news.sky.com/story/coronavirus-trials-...   \n",
       "999      HEALTH  https://www.techexplorist.com/study-demonstrat...   \n",
       "\n",
       "                     domain       published_date  \\\n",
       "0            eurekalert.org  2020-08-06 13:59:45   \n",
       "1                  pulse.ng  2020-08-12 15:14:19   \n",
       "2             express.co.uk  2020-08-13 21:01:00   \n",
       "3                  ndtv.com  2020-08-03 22:18:26   \n",
       "4                 thesun.ie  2020-08-12 19:54:36   \n",
       "..                      ...                  ...   \n",
       "995      androidcentral.com  2020-08-07 17:12:33   \n",
       "996                 cnn.com  2020-08-17 17:10:00   \n",
       "997  tenterfieldstar.com.au  2020-08-13 03:26:06   \n",
       "998            news.sky.com  2020-08-13 13:22:58   \n",
       "999       techexplorist.com  2020-08-10 07:47:00   \n",
       "\n",
       "                                                 title lang   id  \n",
       "0    A closer look at water-splitting's solar fuel ...   en    0  \n",
       "1    An irresistible scent makes locusts swarm, stu...   en    1  \n",
       "2    Artificial intelligence warning: AI will know ...   en    2  \n",
       "3     Glaciers Could Have Sculpted Mars Valleys: Study   en    3  \n",
       "4    Perseid meteor shower 2020: What time and how ...   en    4  \n",
       "..                                                 ...  ...  ...  \n",
       "995  The Mate 40 will be the last Huawei phone with...   en  995  \n",
       "996  Early humans knew how to make comfy, pest-free...   en  996  \n",
       "997           Regional Vic set for virus testing blitz   en  997  \n",
       "998  Coronavirus: Trials of second contact-tracing ...   en  998  \n",
       "999  The study demonstrates new treatment for prion...   en  999  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking subset for making faster executaiton for the rest of the notebook\n",
    "pdf_subset = pdf.head(1000)\n",
    "pdf_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7f7b34-187e-440d-9ea9-7844156f1813",
   "metadata": {},
   "source": [
    "# Tranforming data into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a66063b81b2eddd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def example_create_fn(doc1: pd.Series) -> InputExample:\n",
    "    \"\"\"\n",
    "    Helper function that outputs a sentence_transformer guid, label, and text\n",
    "    \"\"\"\n",
    "    return InputExample(texts=[doc1])\n",
    "\n",
    "faiss_train_examples = pdf_subset.apply(lambda x: example_create_fn(x[\"title\"]), axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db5b0284-3128-4792-916b-58ff0659f56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sentence_transformers.readers.InputExample.InputExample at 0x7f17f5f25f90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_train_examples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ddc679-31ec-42fd-9b11-13820689f565",
   "metadata": {},
   "source": [
    "# Converting Vectorize text into Embedding vectos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c7e7bd39c79ed30",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".gitattributes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.18k/1.18k [00:00<00:00, 1.70MB/s]\n",
      "1_Pooling/config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:00<00:00, 272kB/s]\n",
      "README.md: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10.6k/10.6k [00:00<00:00, 4.62MB/s]\n",
      "config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 612/612 [00:00<00:00, 701kB/s]\n",
      "config_sentence_transformers.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 130kB/s]\n",
      "data_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39.3k/39.3k [00:00<00:00, 164kB/s]\n",
      "pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90.9M/90.9M [00:27<00:00, 3.36MB/s]\n",
      "sentence_bert_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 53.0/53.0 [00:00<00:00, 53.9kB/s]\n",
      "special_tokens_map.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 142kB/s]\n",
      "tokenizer.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 713kB/s]\n",
      "tokenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 350/350 [00:00<00:00, 501kB/s]\n",
      "train_script.py: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13.2k/13.2k [00:00<00:00, 5.81MB/s]\n",
      "vocab.txt: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 516kB/s]\n",
      "modules.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 349/349 [00:00<00:00, 1.02MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 384)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"all-MiniLM-L6-v2\"\n",
    ")  # Use a pre-cached model\n",
    "faiss_title_embedding = model.encode(pdf_subset.title.values.tolist())\n",
    "len(faiss_title_embedding), len(faiss_title_embedding[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12d12201-bbfb-44f7-82f5-35ed2dcca01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1127055 ,  0.04076536,  0.02181419, ..., -0.01874597,\n",
       "        -0.03136873,  0.06824831],\n",
       "       [-0.02187158, -0.03349994,  0.07321803, ...,  0.0336232 ,\n",
       "        -0.00563892, -0.00630977],\n",
       "       [ 0.01608373,  0.00279446, -0.01504421, ..., -0.00706244,\n",
       "         0.00905907, -0.02835049],\n",
       "       ...,\n",
       "       [ 0.0150693 ,  0.04583018, -0.061145  , ..., -0.07814188,\n",
       "        -0.08025027,  0.01337818],\n",
       "       [-0.07082236,  0.0064382 ,  0.00809321, ..., -0.05520818,\n",
       "        -0.03652045,  0.07594129],\n",
       "       [-0.06321976,  0.0446152 , -0.07385813, ...,  0.06559421,\n",
       "         0.03276759,  0.09070996]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_title_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b05244f-907a-481e-956d-36315ec3c6ad",
   "metadata": {},
   "source": [
    "### Step 3: Saving embedding vectors to FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdda109d-8592-4036-b6ee-8c3023a8c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAGIC \n",
    "# MAGIC Below, we create the FAISS index object based on our embedding vectors, normalize vectors, and add these vectors to the FAISS index. \n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "pdf_to_index = pdf_subset.set_index([\"id\"], drop=False)\n",
    "id_index = np.array(pdf_to_index.id.values).flatten().astype(\"int\")\n",
    "content_encoded_normalized = faiss_title_embedding.copy()\n",
    "faiss.normalize_L2(content_encoded_normalized)\n",
    "index_content = faiss.IndexIDMap(faiss.IndexFlatIP(len(faiss_title_embedding[0])))\n",
    "index_content.add_with_ids(content_encoded_normalized, id_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c444013c-f37e-4685-93ba-cd3d539c3118",
   "metadata": {},
   "source": [
    "## Step 4: Search for relevant documents\n",
    "We define a search function below to first vectorize our query text, and then search for the vectors with the closest distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "902e99323b1c548b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def search_content(query, pdf_to_index, k=3):\n",
    "    query_vector = model.encode([query])\n",
    "    faiss.normalize_L2(query_vector)\n",
    "\n",
    "    # We set k to limit the number of vectors we want to return\n",
    "    top_k = index_content.search(query_vector, k)\n",
    "    ids = top_k[1][0].tolist()\n",
    "    similarities = top_k[0][0].tolist()\n",
    "    results = pdf_to_index.loc[ids]\n",
    "    results[\"similarities\"] = similarities\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682b7d1b-f66b-4aac-b1dd-7acaab3a1b68",
   "metadata": {},
   "source": [
    "## Step 4.1: Searching the similar vectors\n",
    "Now you can query for similar content! Notice that you did not have to configure any database networks beforehand nor pass in any credentials. FAISS works locally with your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "554a9ddb40231f38",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>link</th>\n",
       "      <th>domain</th>\n",
       "      <th>published_date</th>\n",
       "      <th>title</th>\n",
       "      <th>lang</th>\n",
       "      <th>id</th>\n",
       "      <th>similarities</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>https://www.pushsquare.com/news/2020/08/random...</td>\n",
       "      <td>pushsquare.com</td>\n",
       "      <td>2020-08-03 16:30:00</td>\n",
       "      <td>Random: You Can Pick Up and Pet Cats in Assass...</td>\n",
       "      <td>en</td>\n",
       "      <td>176</td>\n",
       "      <td>0.391902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>HEALTH</td>\n",
       "      <td>https://www.news-medical.net/news/20200813/Res...</td>\n",
       "      <td>news-medical.net</td>\n",
       "      <td>2020-08-13 05:18:00</td>\n",
       "      <td>Researchers explore social behavior of animals...</td>\n",
       "      <td>en</td>\n",
       "      <td>975</td>\n",
       "      <td>0.376784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>https://www.gematsu.com/2020/08/ghostwire-toky...</td>\n",
       "      <td>gematsu.com</td>\n",
       "      <td>2020-08-07 16:43:13</td>\n",
       "      <td>Ghostwire: Tokyo confirms dog petting</td>\n",
       "      <td>en</td>\n",
       "      <td>99</td>\n",
       "      <td>0.344058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          topic                                               link  \\\n",
       "id                                                                   \n",
       "176  TECHNOLOGY  https://www.pushsquare.com/news/2020/08/random...   \n",
       "975      HEALTH  https://www.news-medical.net/news/20200813/Res...   \n",
       "99   TECHNOLOGY  https://www.gematsu.com/2020/08/ghostwire-toky...   \n",
       "\n",
       "               domain       published_date  \\\n",
       "id                                           \n",
       "176    pushsquare.com  2020-08-03 16:30:00   \n",
       "975  news-medical.net  2020-08-13 05:18:00   \n",
       "99        gematsu.com  2020-08-07 16:43:13   \n",
       "\n",
       "                                                 title lang   id  similarities  \n",
       "id                                                                              \n",
       "176  Random: You Can Pick Up and Pet Cats in Assass...   en  176      0.391902  \n",
       "975  Researchers explore social behavior of animals...   en  975      0.376784  \n",
       "99               Ghostwire: Tokyo confirms dog petting   en   99      0.344058  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(search_content(\"animal\", pdf_to_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea8a176-d0f9-4ec9-b794-557054087c65",
   "metadata": {},
   "source": [
    "## Vector Database: Chroma\n",
    "Chroma is an open-source embedding database. The company just raised its [seed funding in April 2023](https://www.trychroma.com/blog/seed) and is quickly becoming popular to support LLM-based applications. \n",
    "Up until now, we haven't done the last step of conducting Q/A with a language model yet. We are going to demonstrate this with Chroma, a vector database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27701e45-e2b6-477c-a77d-47b0e5bfd84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.9.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.14.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b7ec76e-9d3c-4d20-9f68-81f5236bbd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic-settings\n",
      "  Downloading pydantic_settings-2.1.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pydantic>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings) (2.5.3)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.3.0->pydantic-settings) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.3.0->pydantic-settings) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.3.0->pydantic-settings) (4.9.0)\n",
      "Installing collected packages: pydantic-settings\n",
      "Successfully installed pydantic-settings-2.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pydantic-settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ed2768c-0eb1-4241-82c0-f2f84bfc1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import AnyUrl\n",
    "\n",
    "assert str(AnyUrl(url='https://google.com')) == 'https://google.com/'\n",
    "assert str(AnyUrl(url='https://google.com/')) == 'https://google.com/'\n",
    "assert str(AnyUrl(url='https://google.com/api')) == 'https://google.com/api'\n",
    "assert str(AnyUrl(url='https://google.com/api/')) == 'https://google.com/api/'\n",
    "\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "MyInt = Annotated[int, Field(ge=0)]\n",
    "\n",
    "\n",
    "class Model(BaseModel):\n",
    "    x: MyInt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1c70af451e4882c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "PydanticImportError",
     "evalue": "`BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.5/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.5/u/import-error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPydanticImportError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# from chromadb.config import Settings\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic_settings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSettings\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtelemetry\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClientStartEvent\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/chromadb/config.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSettings\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[1;32m      4\u001b[0m TELEMETRY_WHITELISTED_SETTINGS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchroma_db_impl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchroma_api_impl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchroma_server_ssl_enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/__init__.py:363\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m    361\u001b[0m dynamic_attr \u001b[38;5;241m=\u001b[39m _dynamic_imports\u001b[38;5;241m.\u001b[39mget(attr_name)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dynamic_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_getattr_migration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m package, module_name \u001b[38;5;241m=\u001b[39m dynamic_attr\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_module\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/_migration.py:296\u001b[0m, in \u001b[0;36mgetattr_migration.<locals>.wrapper\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m import_string(REDIRECT_TO_V1[import_path])\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m import_path \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpydantic:BaseSettings\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticImportError(\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`BaseSettings` has been moved to the `pydantic-settings` package. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://docs.pydantic.dev/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion_short()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/migration/#basesettings-has-moved-to-pydantic-settings \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor more details.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    300\u001b[0m     )\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m import_path \u001b[38;5;129;01min\u001b[39;00m REMOVED_IN_V2:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticImportError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimport_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` has been removed in V2.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mPydanticImportError\u001b[0m: `BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.5/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.5/u/import-error"
     ]
    }
   ],
   "source": [
    "\n",
    "import chromadb\n",
    "# from chromadb.config import Settings\n",
    "from pydantic_settings import BaseSettings\n",
    "\n",
    "chroma_client = chromadb.Client(\n",
    "    Settings(\n",
    "        chroma_db_impl=\"duckdb+parquet\"\n",
    "        #persist_directory=DA.paths.user_db,  # this is an optional argument. If you don't supply this, the data will be ephemeral\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22652c72-afe1-45c5-94f9-6a12f646629b",
   "metadata": {},
   "source": [
    "### Chroma Concept: Collection\n",
    "The nice thing about ChromaDB is that if you don't supply a model to vectorize text into embeddings, it will automatically load a default embedding function, i.e. `SentenceTransformerEmbeddingFunction`. It can handle tokenization, embedding, and indexing automatically for you. If you would like to change the embedding model, read [here on how to do that](https://docs.trychroma.com/embeddings). TLDR: you can add an optional `model_name` argument. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9370d043c3a0eb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "collection_name = \"my_news\"\n",
    "\n",
    "# If you have created the collection before, you need to delete the collection first\n",
    "if len(chroma_client.list_collections()) > 0 and collection_name in [chroma_client.list_collections()[0].name]:\n",
    "    chroma_client.delete_collection(name=collection_name)\n",
    "\n",
    "print(f\"Creating collection: '{collection_name}'\")\n",
    "collection = chroma_client.create_collection(name=collection_name)\n",
    "\n",
    "# COMMAND ----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4ba716-1e01-42c1-bb41-ec83d2ece9d3",
   "metadata": {},
   "source": [
    " ### Step 1: Add data to collection\n",
    "  Since we are re-using the same data, we can skip the step of reading data. As mentioned in the text above, Chroma can take care of text vectorization for us, so we can directly add text to the collection and Chroma will convert the text into embeddings behind the scene. \n",
    "Each document must have a unique `id` associated with it and it is up to you to check that there are no duplicate ids.\n",
    "Adding data to collection will take some time to run, especially when there is a lot of data. In the cell below, we intentionally write only a subset of data to the collection to speed things up. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28262c7d-dc03-40cc-bb80-2070d2a18fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pdf_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec5f5a42956667",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "collection.add(\n",
    "    documents=pdf_subset[\"title\"][:100].tolist(),\n",
    "    metadatas=[{\"topic\": topic} for topic in pdf_subset[\"topic\"][:100].tolist()],\n",
    "    ids=[f\"id{x}\" for x in range(100)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160ebf4d-ff7d-4e60-b966-6d85a9ab2583",
   "metadata": {},
   "source": [
    "\n",
    "### Step 2: Query for 10 relevant documents on \"space\"\n",
    "\n",
    "We will return 10 most relevant documents. You can think of `10` as 10 nearest neighbors. You can also change the number of results returned as well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5636548eb77172",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import json\n",
    "\n",
    "results = collection.query(query_texts=[\"space\"], n_results=10)\n",
    "\n",
    "print(json.dumps(results, indent=4))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC \n",
    "# MAGIC\n",
    "# MAGIC In addition to conducting relevancy search, we can also add filter statements. Refer to the [documentation](https://docs.trychroma.com/usage-guide#using-where-filters) for more information.\n",
    "\n",
    "# COMMAND ----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e638348a56c722e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "collection.delete(ids=[\"id0\"])\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC The record with `ids=0` is no longer present.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "collection.get(\n",
    "    ids=[\"id0\"],\n",
    ")\n",
    "\n",
    "# COMMAND ----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77bfe3-eded-4858-8d2c-d1e0babfae49",
   "metadata": {},
   "source": [
    "### Bonus: Add filter statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59795e64d32c64a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "collection.query(query_texts=[\"space\"], where={\"topic\": \"SCIENCE\"}, n_results=10)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### Bonus: Update data in a collection\n",
    "# MAGIC\n",
    "# MAGIC Unlike a vector library, vector databases support changes to the data so we can update or delete data. \n",
    "# MAGIC\n",
    "# MAGIC Indeed, we can update or delete data in a Chroma collection. \n",
    "\n",
    "# COMMAND ----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef0878620dd5ee3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC We can also update a specific data point.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "collection.get(\n",
    "    ids=[\"id2\"],\n",
    ")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "collection.update(\n",
    "    ids=[\"id2\"],\n",
    "    metadatas=[{\"topic\": \"TECHNOLOGY\"}],\n",
    ")\n",
    "\n",
    "# COMMAND ----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecce37bdfc71492",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Prompt engineering for question answering \n",
    "# MAGIC\n",
    "# MAGIC Now that we have identified documents about space from the news dataset, we can pass these documents as additional context for a language model to generate a response based on them! \n",
    "# MAGIC\n",
    "# MAGIC We first need to pick a `text-generation` model. Below, we use a Hugging Face model. You can also use OpenAI as well, but you will need to get an Open AI token and [pay based on the number of tokens](https://openai.com/pricing). \n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_id = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir=DA.paths.datasets)\n",
    "lm_model = AutoModelForCausalLM.from_pretrained(model_id, cache_dir=DA.paths.datasets)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=lm_model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# COMMAND ----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3e6305fbb437a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# MAGIC %md\n",
    "# MAGIC Here's where prompt engineering, which is developing prompts, comes in. We pass in the context in our `prompt_template` but there are numerous ways to write a prompt. Some prompts may generate better results than the others and it requires some experimentation to figure out how best to talk to the model. Each language model behaves differently to prompts. \n",
    "# MAGIC\n",
    "# MAGIC Our prompt template below is inspired from a [2023 paper on program-aided language model](https://arxiv.org/pdf/2211.10435.pdf). The authors have provided their sample prompt template [here](https://github.com/reasoning-machines/pal/blob/main/pal/prompt/date_understanding_prompt.py).\n",
    "# MAGIC\n",
    "# MAGIC The following links also provide some helpful guidance on prompt engineering: \n",
    "# MAGIC - [Prompt engineering with OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)\n",
    "# MAGIC - [GitHub repo that compiles best practices to interact with ChatGPT](https://github.com/f/awesome-chatgpt-prompts)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "question = \"What's the latest news on space development?\"\n",
    "context = \" \".join([f\"#{str(i)}\" for i in results[\"documents\"][0]])\n",
    "prompt_template = f\"Relevant context: {context}\\n\\n The user's question: {question}\"\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "lm_response = pipe(prompt_template)\n",
    "print(lm_response[0][\"generated_text\"])\n",
    "\n",
    "# COMMAND ----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC\n",
    "# MAGIC Yay, you have just completed the implementation of your first text vectorization, search, and question answering workflow (that requires prompt engineering)!\n",
    "# MAGIC\n",
    "# MAGIC In the lab, you will apply your newly gained knowledge to a different dataset. You can also check out the optional modules on Pinecone and Weaviate to learn how to set up vector databases that offer enterprise offerings.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md-sandbox\n",
    "# MAGIC &copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
    "# MAGIC Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "# MAGIC <br/>\n",
    "# MAGIC <a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
